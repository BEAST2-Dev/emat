package emat.stochasticmapping;


import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import org.apache.commons.math3.util.CombinatoricsUtils;

import beast.base.util.Randomizer;


/**
 * Adapted from code generated by gemini-2.5-pro-preview-05-06 
 */
public class UniformisationStochasticMapping implements StochasticMapping {

    // Max number of jumps to consider when sampling N.
    // Should be large enough, e.g., lambdaMax * totalTime + 10 * sqrt(lambdaMax * totalTime)
    public static final int M_MAX_JUMPS_DEFAULT = 20; 
    private int M_MAX_JUMPS;


    public UniformisationStochasticMapping() {
        this.M_MAX_JUMPS = M_MAX_JUMPS_DEFAULT;
    }

    public UniformisationStochasticMapping(int mMaxJumps) {
        this.M_MAX_JUMPS = mMaxJumps;
        if (M_MAX_JUMPS > 20) {
        	// due to factorial(n) getting out of reach
        	throw new IllegalArgumentException("Can only handle up to 20 jumps");
        }
    }

    double[][] rateMatrixR;
    double lambdaMax;
    double[][] qUnif;
    List<double[][]> qUnifPowers;
    
    double[] weightsN;

    @Override
    public void setRatematrix(double[][] rateMatrixR) {
    	this.rateMatrixR = rateMatrixR;
    	
        int numStates = rateMatrixR.length;

        // --- Step 0: Precomputation & Initialization ---
        lambdaMax = 0.0;
        for (int i = 0; i < numStates; i++) {
            if (-rateMatrixR[i][i] > lambdaMax) {
                lambdaMax = -rateMatrixR[i][i];
            }
        }
        
        qUnif = getQUnif(rateMatrixR, lambdaMax);

        // Precompute powers of Q_unif to avoid re-computation
        qUnifPowers = new ArrayList<>();
        qUnifPowers.add(identity(numStates)); // Q_unif^0

        for (int n = 0; n <= M_MAX_JUMPS; n++) {
            if (n > 0) {
                qUnifPowers.add(multiply(qUnifPowers.get(n - 1), qUnif));
            }
        }

    }
    
    private double [] setUpWeights(int startState,
            int endState,
            double totalTime) {
        double[] weightsN = new double[M_MAX_JUMPS+1];
        double p_ij_t_denominator = 0.0; // This is P(X(T)=j | X(0)=i)

        for (int n = 0; n <= M_MAX_JUMPS; n++) {
            double[][] qUnifPowN = qUnifPowers.get(n);

            double poissonTerm;
            if (lambdaMax * totalTime == 0 && n == 0) { // Handle 0^0 case for Poisson
                 poissonTerm = Math.exp(-lambdaMax * totalTime);
            } else if (lambdaMax * totalTime == 0 && n > 0) {
                 poissonTerm = 0;
            } else {
                 poissonTerm = Math.exp(-lambdaMax * totalTime) * Math.pow(lambdaMax * totalTime, n) / CombinatoricsUtils.factorial(n);
            }
            
            double q_unif_n_ij = qUnifPowN[startState][endState];
            double weight = poissonTerm * q_unif_n_ij;
            weightsN[n] = weight;
            // weightsN.add(weight);
            p_ij_t_denominator += weight;
        }

        if (p_ij_t_denominator <= 1e-100) { // Numerically zero
            System.err.println("Path from " + startState + " to " + endState + " in time " + totalTime + " is impossible (P_ij(t) ~ 0).");
            return null;
        }
        return weightsN;
    }

    @Override
    public List<TimeStateInterval> generatePath(
    		int site,
            int startState,
            int endState,
            double totalTime) {

        int numStates = rateMatrixR.length;

        // --- Step 0: Precomputation & Initialization ---
        if (lambdaMax == 0) { // All rates are zero
             if (startState == endState) {
                List<TimeStateInterval> path = new ArrayList<>();
                path.add(new TimeStateInterval(site, startState, 0, totalTime));
                return path;
            } else {
                System.err.println("Error: LambdaMax is 0, but start and end states differ.");
                return null; // Or throw exception
            }
        }


        // --- Step 1: Sample the Number of Uniformised Jumps (N) ---
        weightsN = setUpWeights(startState, endState, totalTime);
        int N = Randomizer.randomChoicePDF(weightsN); 


        // --- Step 2: Sample the Jump Times (tau_1, ..., tau_N) ---
        double[] jumpTimes = new double[N];
        for (int i = 0; i < N; i++) {
            jumpTimes[i] = Randomizer.nextDouble() * totalTime;
        }
        Arrays.sort(jumpTimes);


        // --- Step 3: Sample the Sequence of States (S_0, ..., S_N) ---
        int[] stateSequence = new int[N + 1];
        stateSequence[0] = startState;

        for (int k = 1; k <= N; k++) { // For S_k (state AFTER k-th jump)
            int prevState = stateSequence[k - 1];
            double[] transitionProbsToNextCandidates = new double[numStates];
            double sumProbs = 0.0;

            int remainingJumps = N - k;
            double[][] qUnifPowRemaining = qUnifPowers.get(remainingJumps); // Use precomputed

            // TODO: precalculate transitionProbsToNextCandidates[remainingJumps][prev][end][states] 
            for (int nextCandidateState = 0; nextCandidateState < numStates; nextCandidateState++) {
                double prob = qUnif[prevState][nextCandidateState] * qUnifPowRemaining[nextCandidateState][endState];
                transitionProbsToNextCandidates[nextCandidateState] = prob;
                sumProbs += prob;
            }

            if (sumProbs <= 1e-100) { // Should not happen if P_ij(t) > 0 and N is sampled correctly
                System.err.println("Error: Stuck during state sequence sampling at k=" + k +". Sum of probabilities is zero. This indicates an issue.");
                // This might happen if M_MAX_JUMPS was too small and N was sampled near the edge
                // or if numerical precision led to an inconsistent state.
                // One recovery could be to force to endState if k=N, but that's a hack.
                 if (k == N) {
                    stateSequence[k] = endState; // Force if last jump
                    System.err.println("Forcing state to endState as k=N.");
                 } else {
                    // A more robust solution might involve re-sampling N or throwing an error
                    System.err.println("Cannot determine next state. Aborting path generation.");
                    return null;
                 }
            } else {
                for (int s = 0; s < numStates; s++) {
                    transitionProbsToNextCandidates[s] /= sumProbs;
                }
                stateSequence[k] = Randomizer.randomChoicePDF(transitionProbsToNextCandidates); 
            }
        }
        
        // Final check: S_N should be endState
        if (N > 0 && stateSequence[N] != endState) {
             // This can happen due to numerical precision or M_MAX_JUMPS issues
            System.err.println("Warning: Sampled stateSequence[N]=" + stateSequence[N] + " != endState=" + endState + ". Forcing S_N = endState.");
            stateSequence[N] = endState;
        } else if (N == 0 && startState != endState) {
             System.err.println("Error: N=0 sampled but startState != endState. Path impossible.");
             return null;
        }


        // --- Step 4: Construct the Stochastic Map (and filter fictitious jumps) ---
        List<TimeStateInterval> path = new ArrayList<>();
        double currentTime = 0.0;
        int currentActualState = startState;

        if (N == 0) {
            if (startState == endState) {
                 path.add(new TimeStateInterval(site, startState, 0.0, totalTime));
            } else {
                // This case should have been caught by p_ij_t_denominator being zero
                System.err.println("Error: N=0 but startState != endState. Path construction failed.");
                return null;
            }
        } else {
            for (int k = 0; k < N; k++) { // Iterate through N jumps, creating N+1 intervals
                double jumpOccursAt = jumpTimes[k];
                int stateBeforeThisJump = stateSequence[k]; // S_k
                int stateAfterThisJump = stateSequence[k+1]; // S_{k+1}

                if (stateBeforeThisJump != currentActualState) { // Should not happen if logic is correct
                     System.err.println("State tracking error before jump " + k);
                }

                // Add interval for S_k, from currentTime up to jumpTime[k]
                // Only add if it's a new state OR it's the first segment
                if (k == 0 || stateBeforeThisJump != currentActualState ) {
                    if (currentTime < jumpOccursAt) { // Avoid zero-duration intervals if state doesn't change
                         path.add(new TimeStateInterval(site, currentActualState, currentTime, jumpOccursAt));
                    }
                } else { // stateBeforeThisJump == currentActualState, extend previous interval
                    if (!path.isEmpty()) {
                        TimeStateInterval last = path.remove(path.size()-1);
                        if (last.state() == currentActualState) { // Should always be true
                           path.add(new TimeStateInterval(site, currentActualState, last.startTime(), jumpOccursAt));
                        } else { // Should not happen
                           path.add(last); // put it back
                           path.add(new TimeStateInterval(site, currentActualState, currentTime, jumpOccursAt));
                        }
                    } else { // First interval, but state might be same as start for a fictitious first jump
                         path.add(new TimeStateInterval(site, currentActualState, currentTime, jumpOccursAt));
                    }
                }
                currentTime = jumpOccursAt;
                currentActualState = stateAfterThisJump;
            }
            // Add the last interval, from the Nth jump time to totalTime
            if (currentTime < totalTime || path.isEmpty()) { // path can be empty if all jumps were fictitious at time 0
                 if (!path.isEmpty() && path.get(path.size()-1).state() == currentActualState) {
                    TimeStateInterval last = path.remove(path.size()-1);
                    path.add(new TimeStateInterval(site, currentActualState, last.startTime(), totalTime));
                 } else {
                    path.add(new TimeStateInterval(site, currentActualState, currentTime, totalTime));
                 }
            }
        }
        
        return filterPath(path); // Filter out zero-duration intervals and merge
    }

    private List<TimeStateInterval> filterPath(List<TimeStateInterval> rawPath) {
        if (rawPath == null || rawPath.isEmpty()) {
            return rawPath;
        }
        List<TimeStateInterval> filtered = new ArrayList<>();
        TimeStateInterval current = rawPath.get(0);

        for (int i = 1; i < rawPath.size(); i++) {
            TimeStateInterval next = rawPath.get(i);
            if (next.state() == current.state() && Math.abs(next.startTime() - current.endTime()) < 1e-9) { 
            	// Merge
                current = new TimeStateInterval(current.site(), current.state(), current.startTime(), next.endTime());
            } else { 
            	// Different state or non-contiguous
                if (Math.abs(current.endTime() - current.startTime()) > 1e-9) { // Add if non-zero duration
                    filtered.add(current);
                }
                current = next;
            }
        }
        if (Math.abs(current.endTime() - current.startTime()) > 1e-9) {
             filtered.add(current); // Add the last processed interval
        }
        return filtered;
    }
    
//    private int sampleFromDiscreteDistribution(double[] probabilities) {
//        double randVal = Randomizer.nextDouble();
//        double cumulativeProb = 0.0;
//        for (int i = 0; i < probabilities.length; i++) {
//            cumulativeProb += probabilities[i];
//            if (randVal < cumulativeProb) {
//                return i;
//            }
//        }
//        return probabilities.length - 1; // Fallback
//    }
//

    /** return matrix I+R/lambdaMax **/
    double [][] getQUnif(double [][] rateMatrixR, double lambdaMax) {
//		return add(
//		        identity(numStates),
//		        multiplyByScalar(rateMatrixR, 1.0 / lambdaMax)
        int rows = rateMatrixR.length;
        int cols = rateMatrixR[0].length;
        double[][] result = new double[rows][cols];
        for (int i = 0; i < rows; i++) {
            for (int j = 0; j < cols; j++) {
                result[i][j] = rateMatrixR[i][j] /lambdaMax;
            }
            result[i][i] += 1.0;
        }
        return result;
    }
    
	public static double[][] multiply(double[][] a, double[][] b) {
        int rowsA = a.length;
        int colsA = a[0].length;
        int colsB = b[0].length;
        if (colsA != b.length) {
            throw new IllegalArgumentException("Matrix dimensions incompatible for multiplication.");
        }
        double[][] result = new double[rowsA][colsB];
        for (int i = 0; i < rowsA; i++) {
            for (int j = 0; j < colsB; j++) {
                for (int k = 0; k < colsA; k++) {
                    result[i][j] += a[i][k] * b[k][j];
                }
            }
        }
        return result;
    }

	public static double[][] identity(int size) {
        double[][] id = new double[size][size];
        for (int i = 0; i < size; i++) {
            id[i][i] = 1.0;
        }
        return id;
    }



}